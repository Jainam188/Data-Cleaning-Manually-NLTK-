# Data-Cleaning-Manually and NLTK
Cleaning text data by dividing it into words, Manually or using NLTK Library 

taken the text from the book Metamorphosis by Franz Kafka.

What need to be cleaned?

1 punctuation like commas, apostrophes, quotes, question marks, and more

2 hyphenated descriptions like “armour-like”

3 a lot of use of the dash (“-“) to continue sentences

4 Text often has a variety of capitalizations

there are some small changes also needs to be covered. It's totally depend on your data.

There are mainly two ways to clean data

1 Manually

2 Using Natural Language ToolKit(NLTK) Library

I have done it in both ways.

I personally think that NLTK has some cool inbuild function that can help in many ways,  but if you really want to learn how the data cleaning work than first go with manually after that you can go with NLTK.

one of the main feature is to remove stamming from the word.

For more Understanding visit 

https://machinelearningmastery.com/clean-text-machine-learning-python/
By Jason Brownlee
